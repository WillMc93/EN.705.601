{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.) Load libraries/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from itertools import product\n",
    "from os.path import isdir, isfile\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import  cross_validate, cross_val_score, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set up datapath\n",
    "base_path = './datasets/petsounds/cats_dogs/'\n",
    "\n",
    "if not isdir(base_path):\n",
    "    print(f\"The dataset path {base_path} doesn't seem to exist. Please make sure the path to the data is correct.\")\n",
    "\n",
    "# Lambda to construct full path to cat/dog files\n",
    "route = lambda x: base_path + x    \n",
    "    \n",
    "# Get dictionary of sounds\n",
    "cat_file = 'cat_{}.wav'\n",
    "dog_file = 'dog_barking_{}.wav'\n",
    "\n",
    "pet_sounds = {'cat': [], 'dog': []}\n",
    "for i in range(0, 168):\n",
    "    this_cat = cat_file.format(i)\n",
    "    \n",
    "    if isfile(route(this_cat)):\n",
    "        pet_sounds['cat'].append(this_cat)\n",
    "        \n",
    "    this_dog = dog_file.format(i)\n",
    "    if isfile(route(this_dog)):\n",
    "        pet_sounds['dog'].append(this_dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.) Pre-process a single file using 20 frequency bins, and 2000 Hz sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7fc812a210a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAMPLING_FRQ = 2000\n",
    "BINS = 20\n",
    "\n",
    "# Process the first cat file\n",
    "x, fs = librosa.load(base_path + pet_sounds['cat'][0], sr=SAMPLING_FRQ)\n",
    "mfccs = librosa.feature.mfcc(x, sr=fs, n_mfcc=BINS)\n",
    "librosa.display.specshow(mfccs, sr=fs, x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.) Process each into X and Y matrices. Apply a classifier and comment on results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up sampling frequency to 4k\n",
    "SAMPLING_FRQ = 4000\n",
    "\n",
    "# Set the FFT length; this leads to better sklearn accuracy and \n",
    "#     prevents warnings about frame size.\n",
    "# https://librosa.org/doc/main/ioformats.html?highlight=n_fft\n",
    "# https://librosa.org/doc/main/glossary.html?highlight=n_fft\n",
    "FFT = (2048 * SAMPLING_FRQ) // 22050\n",
    "\n",
    "# Generator function to get all dogs/cats files and label\n",
    "def get_pet(ps_dict=pet_sounds):\n",
    "    for pet in ['cat', 'dog']:\n",
    "        for i in range(0, len(ps_dict[pet])):\n",
    "            yield(ps_dict[pet][i], pet)\n",
    "        \n",
    "    return None\n",
    "\n",
    "# Function to format a scores array into a string for clean output\n",
    "def score_string(scores):\n",
    "    score_str = ''\n",
    "    for idx, score in enumerate(scores):\n",
    "        score_str += f'{score:.3f}'\n",
    "\n",
    "        if idx < len(scores)-1:\n",
    "            score_str += ', '\n",
    "    return score_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert each file into a waveform and store to MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 83 ms, total: 24 s\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ps_mfcc = []\n",
    "\n",
    "for file, pet in get_pet():\n",
    "    wf, sr = librosa.load(route(file), sr=SAMPLING_FRQ)\n",
    "    mfccs = librosa.feature.mfcc(wf, sr=sr, n_mfcc=BINS)\n",
    "    \n",
    "    mfccs = mfccs.T\n",
    "    \n",
    "    ps_mfcc += [(mfccs, pet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some sklearn\n",
    "\n",
    "Parameters for SVC were found through GridSearchCV, but it took 2 hours and I was mad the results favoured SVC so I deleted it. Luckily, this cell doesn't take too long (about 30 seconds).\n",
    "\n",
    "For reference, I also tried RandomForestClassifier and K-Nearest Neighbors, both of which performed similarly but worse.\n",
    "\n",
    "Stratified K-Fold vs regualar K-Fold seems to not change the outcomes very much here (expected due to class balance). \n",
    "Shuffling the K-Fold improves the scores by about 5% in either K-Fold variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and Y\n",
    "# I adapated this from the office hours recording after\n",
    "# running into a problem with datatypes for the RNN\n",
    "N = sum([ps.shape[0] for (ps, pet) in ps_mfcc])\n",
    "\n",
    "X = np.zeros((N, BINS))\n",
    "Y = []\n",
    "\n",
    "idx = 0\n",
    "for mfcc, pet in ps_mfcc:\n",
    "    n = mfcc.shape[0]\n",
    "    for jdx in range(n):\n",
    "        X[idx+jdx, :] = mfcc[jdx]\n",
    "        \n",
    "    idx += n\n",
    "    \n",
    "    Y += [0 if pet == 'cat' else 1]*n\n",
    "    \n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVC(C=10, kernel='poly')\n",
      "\tScores: 0.917, 0.900, 0.913, 0.912, 0.915, 0.904, 0.906, 0.917, 0.906, 0.904\n",
      "\tMean: 0.9093\n",
      "\tSTD: 0.0058\n",
      "\n",
      "CPU times: user 36 s, sys: 777 ms, total: 36.8 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Run cross-validation\n",
    "model = SVC(C=10, kernel='poly') \n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True) \n",
    "\n",
    "sk_scores = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Display scores and statistics\n",
    "print(f'Model: {model}')\n",
    "print(f'\\tScores: {score_string(sk_scores)}')\n",
    "print(f'\\tMean: {np.mean(sk_scores):.4f}')\n",
    "print(f'\\tSTD: {np.std(sk_scores):.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.) Use an RNN to classify and compare results with the model above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_signals = len(ps_mfcc)\n",
    "ps_mfcc2 = [None]*n_signals\n",
    "\n",
    "for i in range(n_signals):\n",
    "    ps_mfcc2[i] = (torch.tensor(ps_mfcc[i][0], dtype=torch.float),\n",
    "                   torch.tensor([0 if ps_mfcc[i][1] == 'cat' else 1], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden, n_output, eta=0.0005):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.i2h = nn.Linear(n_features + n_hidden, n_hidden)\n",
    "        self.i2o = nn.Linear(n_features + n_hidden, n_output)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        self.eta = eta  # learning rate\n",
    "        \n",
    "        self.epochs = 50\n",
    "        self.batch_size = 1000\n",
    "        \n",
    "        # loss function, since the last layer is nn.LogSoftmax\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.eta)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), dim=1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.n_hidden)\n",
    "    \n",
    "    def predict(self, sxx):\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            hidden = self.init_hidden()\n",
    "            # sxx = torch.tensor(sxx, dtype=torch.float)\n",
    "            for i in range(sxx.shape[0]):\n",
    "                output, hidden = self.forward(sxx[i].reshape(1,self.n_features), hidden)\n",
    "                y_pred.append(0 if output[0][0]>output[0][1] else 1)\n",
    "            \n",
    "        return y_pred\n",
    "\n",
    "    def train(self, mfccs, epoch=None):\n",
    "           \n",
    "        tot_loss = 0\n",
    "                 \n",
    "        for idx, (sxx, y) in enumerate(mfccs):\n",
    "            hidden = self.init_hidden()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            for jdx in range(sxx.shape[0]):\n",
    "                output, hidden = self.forward(sxx[jdx].reshape(1, self.n_features), hidden)\n",
    "                \n",
    "            loss = self.criterion(output, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "        \n",
    "            tot_loss += loss\n",
    "        \n",
    "            msg = f\"Signal: {idx+1:03d}/{len(mfccs)} | \" \n",
    "            msg += f\"Loss: {loss:6.2f} | Avg. Loss: {tot_loss/(idx+1):6.2f} | {y.data.tolist() [0]}\"\n",
    "        \n",
    "            sys.stderr.write(msg)\n",
    "            sys.stderr.flush()\n",
    "        \n",
    "        return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-981ea446bdc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps_mfcc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBINS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# Run a 10-fold CV w/ RNN\n",
    "scores = []\n",
    "\n",
    "kfold = KFold(n_splits = 10)\n",
    "index = np.arange(len(ps_mfcc2))\n",
    "\n",
    "for cv, train_idx, test_idx in enumerate(kfold.split(index)):\n",
    "    rnn = RNN(BINS, 20, 2)\n",
    "    \n",
    "    training = [ps_mfcc2[i] for i in train_idx]\n",
    "    testing = [ps_mfcc2[i] for i in test_idx]\n",
    "      \n",
    "    # Train\n",
    "    for epo in range(EPOCHS):\n",
    "        msg = f\"\\rCV: {cv} | Epoch: {epo} | \"\n",
    "        sys.stderr.write(msg)\n",
    "        sys.stderr.flush()\n",
    "        \n",
    "        shuffle(training)\n",
    "        rnn.train(training, epo)\n",
    "        \n",
    "    # Test\n",
    "    # Get predictions\n",
    "    y_pred = []\n",
    "    for mfcc in testing:\n",
    "        y_pred += [rnn.predict(mfcc[0])]\n",
    "    \n",
    "    # Get targets\n",
    "    targets = []\n",
    "    for idx, y in enumerate(testing):\n",
    "        targets.append(y[1])\n",
    "    \n",
    "    # Count correct predictions and store as score\n",
    "    score = 0\n",
    "    for pred, tar in zip(y_pred, targets):\n",
    "        score += 1 if pred == tar else 0\n",
    "        \n",
    "    score = score / len(targets)           \n",
    "       \n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_mfcc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
